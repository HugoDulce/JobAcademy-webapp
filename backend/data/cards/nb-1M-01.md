---
deck: "JobAcademy::Uncategorized::1-Use Case"
tags: [uncategorized, mathematical, fill-in-blank]
card_id: "nb-1M-01"
fire_weight: 0.4
notion_last_edited: "2026-02-08T17:07:00.000Z"
concept_node: "BAYES"
---

# nb-1M-01

START
Complete Bayes' theorem:

P(y | x) = ___
END

START
P(y | x) = [ P(x | y) Ã— P(y) ] / P(x)

Where:
- P(y | x) = posterior (what we want)
- P(x | y) = likelihood (what NB models)
- P(y) = prior (class frequency)
- P(x) = evidence (normalizing constant)

NB ignores P(x) for classification (same for all classes).
END
